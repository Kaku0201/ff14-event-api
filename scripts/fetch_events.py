import json
import requests
from bs4 import BeautifulSoup
import os
import time

BASE_URL = "https://www.ff14.co.kr/news/event"
HEADERS = {
    "User-Agent": "Mozilla/5.0"
}
MAX_PAGE = 10  # í˜ì´ì§€ ì œí•œ (ì•ˆì •ì„± í™•ë³´)

def fetch_events():
    events = []
    page = 1

    while page <= MAX_PAGE:
        print(f"ğŸ” í˜ì´ì§€ {page} ìš”ì²­ ì¤‘...")
        res = requests.get(f"{BASE_URL}?page={page}", headers=HEADERS)
        soup = BeautifulSoup(res.text, "html.parser")

        # ì§„í–‰ ì¤‘ ì´ë²¤íŠ¸ ëª©ë¡ ì¶”ì¶œ
        event_list = soup.select("ul.banner_list.event:not(.end)")
        if not event_list:
            print("ğŸ“­ ì§„í–‰ ì¤‘ ì´ë²¤íŠ¸ ì—†ìŒ. ì¢…ë£Œ.")
            break

        cards = event_list[0].select("li")
        if not cards:
            print("ğŸ“­ ì¹´ë“œ ì—†ìŒ. ì¢…ë£Œ.")
            break

        for li in cards:
            a_tag = li.select_one("a")
            title_tag = li.select_one(".txt_box .title .txt")
            date_tag = li.select_one(".date")
            desc_tag = li.select_one(".summary.dot")

            if a_tag and title_tag and date_tag:
                title = title_tag.text.strip()
                date = date_tag.text.strip()
                link = "https://www.ff14.co.kr" + a_tag["href"]
                description = desc_tag.text.strip() if desc_tag else ""

                events.append({
                    "title": title,
                    "date": date,
                    "link": link,
                    "description": description  # âœ… ì„¤ëª… ì¶”ê°€
                })

        print(f"ğŸ“„ í˜ì´ì§€ {page} ì²˜ë¦¬ ì™„ë£Œ. ëˆ„ì  {len(events)}ê±´")
        page += 1
        time.sleep(1)  # ì„œë²„ ë¶€ë‹´ ë°©ì§€

    os.makedirs("events", exist_ok=True)
    with open("events/events.json", "w", encoding="utf-8") as f:
        json.dump(events, f, ensure_ascii=False, indent=2)

    print(f"âœ” ì „ì²´ ì´ë²¤íŠ¸ ìˆ˜: {len(events)}ê±´")

if __name__ == "__main__":
    fetch_events()
